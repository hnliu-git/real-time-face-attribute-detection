{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "main.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "GtRG6osNkpU_"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "# ! cp '/content/drive/MyDrive/KTH/Scalable ML/archive.zip' .\n",
        "# ! unzip archive.zip && rm archive.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ! pip install pytorch-lightning"
      ],
      "metadata": {
        "id": "S0MFEshenE47"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import random\n",
        "import datetime\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch.nn as nn\n",
        "import pytorch_lightning as pl\n",
        "\n",
        "from PIL import Image\n",
        "from torch.optim import AdamW\n",
        "from torchvision import models\n",
        "import torch.nn.functional as F\n",
        "from argparse import ArgumentParser\n",
        "from matplotlib import pyplot as plt\n",
        "from torchvision.transforms import transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint\n",
        "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
        "from pytorch_lightning.callbacks import LearningRateMonitor"
      ],
      "metadata": {
        "id": "hND1pPjwnrde"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load and check raw data"
      ],
      "metadata": {
        "id": "Hycq1XfPnUrm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "folder = 'img_align_celeba/img_align_celeba'\n",
        "\n",
        "imgs = [folder + \"/\" + f for f in sorted(folder)]\n",
        "attrs = pd.read_csv('list_attr_celeba.csv').replace(-1, 0)\n",
        "\n",
        "classes = attrs.columns\n",
        "n_classes = len(classes) - 1\n",
        "id2class = {i:classes[i+1] for i in range(n_classes)}"
      ],
      "metadata": {
        "id": "tnaRkkcimVOw"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class CelebDataset(Dataset):\n",
        "  def __init__(self,df,image_path,transform=None,mode='train'):\n",
        "    super().__init__()\n",
        "    self.attr=df.drop(['image_id'],axis=1)\n",
        "    self.path=image_path\n",
        "    self.image_id=df['image_id']\n",
        "    self.transform=transform\n",
        "    self.mode=mode\n",
        "  \n",
        "  def __len__(self):\n",
        "    return self.image_id.shape[0]\n",
        "\n",
        "  def __getitem__(self,idx:int):\n",
        "    image_name=self.image_id.iloc[idx]\n",
        "    image=Image.open(os.path.join(folder,image_name))\n",
        "    attributes=np.asarray(self.attr.iloc[idx].T,dtype=np.float32)\n",
        "    if self.transform:\n",
        "      image=self.transform(image)\n",
        "    return image, attributes    \n",
        "\n",
        "\n",
        "# function to visualize dataset\n",
        "def imshow(images,attr,idx:int):\n",
        "    images=images.cpu().numpy().transpose((0,2,3,1))\n",
        "    plt.imshow(images[idx] * std + mean)\n",
        "    labels=attrs.columns.tolist()\n",
        "    labels=labels[1:]\n",
        "    att=attr[idx].numpy()\n",
        "    labels=[label for label,a in list(zip(labels,att)) if a==1]\n",
        "    plt.xlabel(\"\\n\".join(labels))\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "mean = [0.485, 0.456, 0.406]\n",
        "std = [0.229, 0.224, 0.225]\n",
        "\n",
        "train_transform=transforms.Compose([transforms.Resize((224,224)),\n",
        "                  transforms.RandomVerticalFlip(p=0.5),\n",
        "                  transforms.RandomHorizontalFlip(p=0.5),\n",
        "                  transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.2),\n",
        "                  transforms.ToTensor(),\n",
        "                  transforms.Normalize(mean=mean, std=std)])\n",
        "\n",
        "valid_transform=transforms.Compose([transforms.Resize((224,224)),\n",
        "                  transforms.ToTensor(),\n",
        "                  transforms.Normalize(mean=mean, std=std)])"
      ],
      "metadata": {
        "id": "vMwm99SFqO4x"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df,test=train_test_split(attrs,test_size=0.1,shuffle=True,random_state=212)\n",
        "valid_df,test_df=train_test_split(test,test_size=0.5,random_state=212)\n",
        " \n",
        "train_data=CelebDataset(train_df,imgs,train_transform)\n",
        "valid_data=CelebDataset(valid_df,imgs,valid_transform)\n",
        "test_data= CelebDataset(test_df,imgs,valid_transform)"
      ],
      "metadata": {
        "id": "YynMypMVyyIo"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_metrics(output, target):\n",
        "  \"\"\"\n",
        "  output: list of tensor from fc, [(B, H)]\n",
        "  target: list of label [B]\n",
        "  \"\"\"\n",
        "  from sklearn.metrics import accuracy_score\n",
        "\n",
        "  predict = [torch.argmax(i, dim=1).cpu() for i in output]\n",
        "  target = [i.cpu() for i in target]\n",
        "\n",
        "  accs = [accuracy_score(y_true=t.numpy(), y_pred=p.numpy()) for t, p in zip(target, predict)]\n",
        "  avg_acc = sum(accs) / len(accs)\n",
        "  min_acc = min(accs)\n",
        "  max_acc = max(accs)\n",
        "\n",
        "  return avg_acc, min_acc, max_acc\n",
        "\n",
        "\n",
        "class MultiBinMobileNet(pl.LightningModule):\n",
        "\n",
        "  def __init__(self, n_classes):\n",
        "    super().__init__()\n",
        "\n",
        "    self.save_hyperparameters()\n",
        "    self.n_classes = n_classes\n",
        "    mnet = models.mobilenet_v2()\n",
        "    \n",
        "    # the input for the classifier should be two-dimensional, but we will have\n",
        "    # [batch_size, channels, width, height]\n",
        "    # so, let's do the spatial averaging: reduce width and height to 1\n",
        "    self.pool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "    self.base_model = mnet.features\n",
        "    self.fcs = [nn.Sequential(nn.Dropout(p=0.2), nn.Linear(in_features=mnet.last_channel, out_features=2)).cuda() for _ in range(n_classes)]\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.base_model(x)\n",
        "    x = self.pool(x)\n",
        "    # reshape from [batch, channels, 1, 1] to [batch, channels] to put it into classifier\n",
        "    x = torch.flatten(x, 1)\n",
        "\n",
        "    return [fc(x) for fc in self.fcs]\n",
        "\n",
        "  def configure_optimizers(self):\n",
        "    optimizer = AdamW(self.parameters(), lr=1e-3)\n",
        "    scheduler = ReduceLROnPlateau(optimizer, mode=\"min\", factor=1e-1, patience=2, verbose=True)\n",
        "    return {'optimizer': optimizer, 'lr_scheduler': scheduler, 'monitor': 'val_loss'}\n",
        "    \n",
        "  \n",
        "  def training_step(self, train_batch, batch_idx):\n",
        "    # Img [bsz, w, h, c]\n",
        "    img, attrs = train_batch\n",
        "    output = self.forward(img)\n",
        "    attrs = torch.unbind(attrs, 1)\n",
        "\n",
        "    train_loss = self.get_loss(output, attrs)\n",
        "    return {'loss': train_loss}\n",
        "\n",
        "  def validation_step(self, val_batch, batch_idx):\n",
        "    img, attrs = val_batch\n",
        "    output = self.forward(img)\n",
        "    attrs = torch.unbind(attrs, 1)\n",
        "\n",
        "    val_loss = self.get_loss(output, attrs)\n",
        "    avg_acc, min_acc, max_acc = calculate_metrics(output, attrs)\n",
        "\n",
        "    return {\"val_loss\": val_loss, 'avg_acc': avg_acc, 'min_acc': min_acc, 'max_acc': max_acc}\n",
        "\n",
        "  def validation_epoch_end(self, outputs):\n",
        "      \"\"\"\"\"\"\n",
        "      val_loss = torch.stack([x[\"val_loss\"] for x in outputs]).mean()\n",
        "      avg_acc = sum([x['avg_acc'] for x in outputs]) / len(outputs)\n",
        "      max_acc = max([x['max_acc'] for x in outputs])\n",
        "      min_acc = min([x['min_acc'] for x in outputs])\n",
        "      self.log(\"val_loss\", val_loss, prog_bar=True, logger=True)\n",
        "      self.log(\"avg_acc\", avg_acc, prog_bar=True, logger=True)\n",
        "      self.log(\"max_acc\", max_acc, prog_bar=True, logger=True)\n",
        "      self.log(\"min_acc\", min_acc, prog_bar=True, logger=True)\n",
        "\n",
        "  def get_loss(self, output, truth):\n",
        "    losses = sum([F.cross_entropy(output[i], truth[i].type(torch.LongTensor).cuda()) for i in range(self.n_classes)])\n",
        "    return losses\n",
        "  "
      ],
      "metadata": {
        "id": "dVrkyddoGsAp"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pl.seed_everything(1234)\n",
        "\n",
        "batch_size = 32\n",
        "n_epochs = 10\n",
        "val_every_n_epoch = 1\n",
        "\n",
        "train_loader=DataLoader(train_data,batch_size=batch_size,shuffle=True,num_workers=2)\n",
        "valid_loader=DataLoader(valid_data,batch_size=batch_size,num_workers=2)\n",
        "test_loader=DataLoader(test_data,batch_size=batch_size,num_workers=2)\n",
        "\n",
        "model = MultiBinMobileNet(n_classes)\n",
        "\n",
        "# Callbacks:\n",
        "checkpoint = ModelCheckpoint(\n",
        "    dirpath='models/ckpts/',\n",
        "    filename=\"./fx-{epoch:02d}-{val_loss:.7f}\",\n",
        "    monitor=\"val_loss\"\n",
        ")\n",
        "\n",
        "earlystopping = EarlyStopping(monitor='val_loss',\n",
        "                              min_delta=0.01,\n",
        "                              patience=5,\n",
        "                              verbose=False,\n",
        "                              mode=\"min\")\n",
        "\n",
        "trainer = pl.Trainer(\n",
        "    gpus=1,\n",
        "    # limit_train_batches=100,\n",
        "    max_epochs=n_epochs,\n",
        "    enable_checkpointing=True,\n",
        "    check_val_every_n_epoch=val_every_n_epoch,\n",
        "    callbacks=[checkpoint, earlystopping, LearningRateMonitor()]\n",
        ")\n",
        "\n",
        "trainer.fit(model, train_loader, valid_loader)"
      ],
      "metadata": {
        "id": "1WkPq2-8Ifry"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MultiBinMobileNet.load_from_checkpoint('/content/models/ckpts/fx-epoch=00-val_loss=9.8684387.ckpt')\n",
        "\n",
        "# use model.forward() to get prediction\n",
        "\n",
        "\n",
        "# convert from id to names using dict\n",
        "\n",
        "id2class\n"
      ],
      "metadata": {
        "id": "p9-q2DJH95Ll"
      },
      "execution_count": 14,
      "outputs": []
    }
  ]
}